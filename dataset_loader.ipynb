{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kaush\\Desktop\\synk-ai\\SYNK-VoiceScribe\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio_filepath', 'text', 'duration', 'lang', 'samples', 'verbatim', 'normalized', 'speaker_id', 'scenario', 'task_name', 'gender', 'age_group', 'job_type', 'qualification', 'area', 'district', 'state', 'occupation', 'verification_report', 'unsanitized_verbatim', 'unsanitized_normalized', '__index_level_0__'],\n",
      "        num_rows: 179327\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['audio_filepath', 'text', 'duration', 'lang', 'samples', 'verbatim', 'normalized', 'speaker_id', 'scenario', 'task_name', 'gender', 'age_group', 'job_type', 'qualification', 'area', 'district', 'state', 'occupation', 'verification_report', 'unsanitized_verbatim', 'unsanitized_normalized', '__index_level_0__'],\n",
      "        num_rows: 2581\n",
      "    })\n",
      "})\n",
      "{'audio_filepath': {'path': '5348024557619869_chunk_1.flac', 'array': array([-0.00161743, -0.00018311,  0.00158691, ...,  0.00466919,\n",
      "        0.00253296, -0.00067139], shape=(113136,)), 'sampling_rate': 16000}, 'text': 'राजस्थान में मनाए जाने वाले मुख्य सांस्कृतिक त्योहार जो हमारे हैं वो हैं जैसे', 'duration': 7.071, 'lang': 'hi', 'samples': 113136, 'verbatim': 'राजस्थान में मनाए जाने वाले मुख्य सांस्कृतिक त्योहार जो हमारे हैं वो हैं जैसे', 'normalized': 'राजस्थान में मनाए जाने वाले मुख्य सांस्कृतिक त्योहार जो हमारे हैं वो हैं जैसे', 'speaker_id': 'S4258000500354303', 'scenario': 'Extempore', 'task_name': 'DOI - Culture', 'gender': 'Female', 'age_group': '18-30', 'job_type': 'Unemployed', 'qualification': 'Undergrad and Grad.', 'area': 'Urban', 'district': 'Jaipur', 'state': 'Rajasthan', 'occupation': 'Housewife', 'verification_report': \"{'sst': False, 'comments': '', 'decision': 'excellent', 'book_read': False, 'off_topic': False, 'low_volume': False, 'stretching': False, 'long_pauses': False, 'echo_present': True, 'unclear_audio': False, 'reading_prompt': False, 'skipping_words': False, 'wrong_language': False, 'mispronunciation': False, 'noise_persistent': False, 'repeating_content': False, 'chatter_persistent': False, 'factual_inaccuracy': False, 'noise_intermittent': False, 'chatter_intermittent': False, 'bad_extempore_quality': False, 'incorrect_text_prompt': False, 'objectionable_content': False}\", 'unsanitized_verbatim': 'राजस्थान में मनाए जाने वाले मुख्य सांस्कृतिक त्योहार जो हमारे हैं वो हैं जैसे', 'unsanitized_normalized': 'राजस्थान में मनाए जाने वाले मुख्य सांस्कृतिक त्योहार जो हमारे हैं वो हैं जैसे', '__index_level_0__': 0}\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict, concatenate_datasets, load_from_disk\n",
    "import os\n",
    "\n",
    "# Set your directory path\n",
    "data_dir = r\"D:\\hf_cache\\ai4bharat___indic_voices\\hindi\\0.0.0\\0eb2969b9f303c3e58cc1820c8e738aaca9d7844\"\n",
    "\n",
    "# List of training shards\n",
    "train_files = [os.path.join(data_dir, f\"indic_voices-train-{i:05d}-of-00044.arrow\") for i in range(44)]\n",
    "\n",
    "# Load each Arrow shard as a Dataset object\n",
    "train_datasets = [Dataset.from_file(f) for f in train_files]\n",
    "train_dataset = concatenate_datasets(train_datasets)\n",
    "\n",
    "# Load validation file\n",
    "valid_file = os.path.join(data_dir, \"indic_voices-valid.arrow\")\n",
    "valid_dataset = Dataset.from_file(valid_file)\n",
    "\n",
    "# Combine into a DatasetDict\n",
    "full_dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": valid_dataset\n",
    "})\n",
    "\n",
    "# Optional: Save for easier future use\n",
    "# full_dataset.save_to_disk(\"indic_voices_hindi\")\n",
    "\n",
    "# Example: Inspect\n",
    "print(full_dataset)\n",
    "print(full_dataset[\"train\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Audio\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Pick a sample\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[43mfull_dataset\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Play the audio\u001b[39;00m\n\u001b[1;32m      7\u001b[0m Audio(sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_filepath\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m'\u001b[39m], rate\u001b[38;5;241m=\u001b[39msample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_filepath\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampling_rate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'full_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "# Pick a sample\n",
    "sample = full_dataset['train'][2]\n",
    "\n",
    "# Play the audio\n",
    "Audio(sample['audio_filepath']['array'], rate=sample['audio_filepath']['sampling_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: یہ ہمارے یہاں پر بخصالی پرمپر آئے اور سموڑاؤں کو درشاتی ہیں  ان سبھی تہاروں سے ہمارہ دھارمیک اور بخصی بھارنے ہماریں تہاروں کی ساتھ\n"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "import tempfile\n",
    "from whisper_transcription import transcribe_audio\n",
    "\n",
    "# Save the numpy array to a temporary .wav file\n",
    "with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmp:\n",
    "    sf.write(tmp.name, sample['audio_filepath']['array'], sample['audio_filepath']['sampling_rate'])\n",
    "    temp_audio_path = tmp.name\n",
    "\n",
    "# Transcribe the audio\n",
    "transcript = transcribe_audio(temp_audio_path)\n",
    "print(\"Transcript:\", transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to speech conversion using INDIC-PARSER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kaush\\Desktop\\synk-ai\\SYNK-VoiceScribe\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kaush\\.cache\\huggingface\\hub\\models--parler-tts--parler-tts-mini-v1.1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The checkpoint you are trying to load has model type `parler_tts` but Transformers does not recognize this architecture. This could be because of an issue with the checkpoint, or because your version of Transformers is out of date.\n\nYou can update Transformers with the command `pip install --upgrade transformers`. If this does not work, and the checkpoint is very new, then there may not be a release version that supports this model yet. In this case, you can get the most up-to-date code by installing Transformers from source with the command `pip install git+https://github.com/huggingface/transformers.git`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaush\\Desktop\\synk-ai\\SYNK-VoiceScribe\\venv\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1131\u001b[39m, in \u001b[36mAutoConfig.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m   1130\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1131\u001b[39m     config_class = \u001b[43mCONFIG_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel_type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaush\\Desktop\\synk-ai\\SYNK-VoiceScribe\\venv\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:833\u001b[39m, in \u001b[36m_LazyConfigMapping.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mapping:\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[32m    834\u001b[39m value = \u001b[38;5;28mself\u001b[39m._mapping[key]\n",
      "\u001b[31mKeyError\u001b[39m: 'parler_tts'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load model directly\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForSeq2SeqLM\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m model = \u001b[43mAutoModelForSeq2SeqLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparler-tts/parler-tts-mini-v1.1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaush\\Desktop\\synk-ai\\SYNK-VoiceScribe\\venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:531\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mquantization_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    529\u001b[39m     _ = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mquantization_config\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m531\u001b[39m config, kwargs = AutoConfig.from_pretrained(\n\u001b[32m    532\u001b[39m     pretrained_model_name_or_path,\n\u001b[32m    533\u001b[39m     return_unused_kwargs=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    534\u001b[39m     code_revision=code_revision,\n\u001b[32m    535\u001b[39m     _commit_hash=commit_hash,\n\u001b[32m    536\u001b[39m     **hub_kwargs,\n\u001b[32m    537\u001b[39m     **kwargs,\n\u001b[32m    538\u001b[39m )\n\u001b[32m    540\u001b[39m \u001b[38;5;66;03m# if torch_dtype=auto was passed here, ensure to pass it on\u001b[39;00m\n\u001b[32m    541\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs_orig.get(\u001b[33m\"\u001b[39m\u001b[33mtorch_dtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaush\\Desktop\\synk-ai\\SYNK-VoiceScribe\\venv\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1133\u001b[39m, in \u001b[36mAutoConfig.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m   1131\u001b[39m         config_class = CONFIG_MAPPING[config_dict[\u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m]]\n\u001b[32m   1132\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1133\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1134\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe checkpoint you are trying to load has model type `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_dict[\u001b[33m'\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1135\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mbut Transformers does not recognize this architecture. This could be because of an \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1136\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33missue with the checkpoint, or because your version of Transformers is out of date.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1137\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou can update Transformers with the command `pip install --upgrade transformers`. If this \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1138\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mdoes not work, and the checkpoint is very new, then there may not be a release version \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1139\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mthat supports this model yet. In this case, you can get the most up-to-date code by installing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1140\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mTransformers from source with the command \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1141\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`pip install git+https://github.com/huggingface/transformers.git`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1142\u001b[39m         )\n\u001b[32m   1143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m config_class.from_dict(config_dict, **unused_kwargs)\n\u001b[32m   1144\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1145\u001b[39m     \u001b[38;5;66;03m# Fallback: use pattern matching on the string.\u001b[39;00m\n\u001b[32m   1146\u001b[39m     \u001b[38;5;66;03m# We go from longer names to shorter names to catch roberta before bert (for instance)\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: The checkpoint you are trying to load has model type `parler_tts` but Transformers does not recognize this architecture. This could be because of an issue with the checkpoint, or because your version of Transformers is out of date.\n\nYou can update Transformers with the command `pip install --upgrade transformers`. If this does not work, and the checkpoint is very new, then there may not be a release version that supports this model yet. In this case, you can get the most up-to-date code by installing Transformers from source with the command `pip install git+https://github.com/huggingface/transformers.git`"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"parler-tts/parler-tts-mini-v1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to c:\\users\\kaush\\appdata\\local\\temp\\pip-req-build-d0p8ruft\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 40a493c7ed4f19f08eadb0639cf26d49bfa5e180\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: filelock in c:\\users\\kaush\\desktop\\synk-ai\\synk-voicescribe\\venv\\lib\\site-packages (from transformers==4.52.0.dev0) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\kaush\\desktop\\synk-ai\\synk-voicescribe\\venv\\lib\\site-packages (from transformers==4.52.0.dev0) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\kaush\\desktop\\synk-ai\\synk-voicescribe\\venv\\lib\\site-packages (from transformers==4.52.0.dev0) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kaush\\desktop\\synk-ai\\synk-voicescribe\\venv\\lib\\site-packages (from transformers==4.52.0.dev0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kaush\\desktop\\synk-ai\\synk-voicescribe\\venv\\lib\\site-packages (from transformers==4.52.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kaush\\desktop\\synk-ai\\synk-voicescribe\\venv\\lib\\site-packages (from transformers==4.52.0.dev0) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\kaush\\desktop\\synk-ai\\synk-voicescribe\\venv\\lib\\site-packages (from transformers==4.52.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\kaush\\desktop\\synk-ai\\synk-voicescribe\\venv\\lib\\site-packages (from transformers==4.52.0.dev0) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\kaush\\desktop\\synk-ai\\synk-voicescribe\\venv\\lib\\site-packages (from transformers==4.52.0.dev0) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\kaush\\desktop\\synk-ai\\synk-voicescribe\\venv\\lib\\site-packages (from transformers==4.52.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kaush\\desktop\\synk-ai\\synk-voicescribe\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\kaush\\desktop\\synk-ai\\synk-voicescribe\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (4.13.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\kaush\\desktop\\synk-ai\\synk-voicescribe\\venv\\lib\\site-packages (from tqdm>=4.27->transformers==4.52.0.dev0) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kaush\\desktop\\synk-ai\\synk-voicescribe\\venv\\lib\\site-packages (from requests->transformers==4.52.0.dev0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kaush\\desktop\\synk-ai\\synk-voicescribe\\venv\\lib\\site-packages (from requests->transformers==4.52.0.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kaush\\desktop\\synk-ai\\synk-voicescribe\\venv\\lib\\site-packages (from requests->transformers==4.52.0.dev0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kaush\\desktop\\synk-ai\\synk-voicescribe\\venv\\lib\\site-packages (from requests->transformers==4.52.0.dev0) (2025.4.26)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml): started\n",
      "  Building wheel for transformers (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for transformers: filename=transformers-4.52.0.dev0-py3-none-any.whl size=11327664 sha256=a5e7aa9fa41037775db171c6d36e5f38f950cc677f210df9c60900a7ce5f27eb\n",
      "  Stored in directory: C:\\Users\\kaush\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-qhcyd68r\\wheels\\90\\86\\bb\\8ad35b428289429952d8316d30f64abedae0ab2fcee0f4f46f\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.51.3\n",
      "    Uninstalling transformers-4.51.3:\n",
      "      Successfully uninstalled transformers-4.51.3\n",
      "Successfully installed transformers-4.52.0.dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git 'C:\\Users\\kaush\\AppData\\Local\\Temp\\pip-req-build-d0p8ruft'\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/parler-tts.git\n",
      "  Cloning https://github.com/huggingface/parler-tts.git to c:\\users\\kaush\\appdata\\local\\temp\\pip-req-build-7q7x0abj\n",
      "  Resolved https://github.com/huggingface/parler-tts.git to commit d108732cd57788ec86bc857d99a6cabd66663d68\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting descript-audiotools@ git+https://github.com/descriptinc/audiotools (from parler_tts==0.2.2)\n",
      "  Cloning https://github.com/descriptinc/audiotools to c:\\users\\kaush\\appdata\\local\\temp\\pip-install-ao8hdcjx\\descript-audiotools_26bb73309e0d40e0ba87477ea0e7df58\n",
      "  Resolved https://github.com/descriptinc/audiotools to commit 348ebf2034ce24e2a91a553e3171cb00c0c71678\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting transformers<=4.46.1,>=4.46.1 (from parler_tts==0.2.2)\n",
      "  Downloading transformers-4.46.1-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\kaush\\desktop\\synk-ai\\synk-voicescribe\\venv\\lib\\site-packages (from parler_tts==0.2.2) (2.7.0)\n",
      "Collecting sentencepiece (from parler_tts==0.2.2)\n",
      "  Downloading sentencepiece-0.2.0.tar.gz (2.6 MB)\n",
      "     ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "     ---------------------------------------- 2.6/2.6 MB 21.5 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/parler-tts.git 'C:\\Users\\kaush\\AppData\\Local\\Temp\\pip-req-build-7q7x0abj'\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/descriptinc/audiotools 'C:\\Users\\kaush\\AppData\\Local\\Temp\\pip-install-ao8hdcjx\\descript-audiotools_26bb73309e0d40e0ba87477ea0e7df58'\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [48 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \u001b[35m\"C:\\Users\\kaush\\Desktop\\synk-ai\\SYNK-VoiceScribe\\venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m389\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "          \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\kaush\\Desktop\\synk-ai\\SYNK-VoiceScribe\\venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m373\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "          json_out[\"return_val\"] = \u001b[31mhook\u001b[0m\u001b[1;31m(**hook_input[\"kwargs\"])\u001b[0m\n",
      "                                   \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\kaush\\Desktop\\synk-ai\\SYNK-VoiceScribe\\venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m143\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "          return hook(config_settings)\n",
      "        File \u001b[35m\"C:\\Users\\kaush\\AppData\\Local\\Temp\\pip-build-env-hfwtdl_3\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m331\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "          return \u001b[31mself._get_build_requires\u001b[0m\u001b[1;31m(config_settings, requirements=[])\u001b[0m\n",
      "                 \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\kaush\\AppData\\Local\\Temp\\pip-build-env-hfwtdl_3\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m301\u001b[0m, in \u001b[35m_get_build_requires\u001b[0m\n",
      "          \u001b[31mself.run_setup\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\kaush\\AppData\\Local\\Temp\\pip-build-env-hfwtdl_3\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m512\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "          \u001b[31msuper().run_setup\u001b[0m\u001b[1;31m(setup_script=setup_script)\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\kaush\\AppData\\Local\\Temp\\pip-build-env-hfwtdl_3\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m317\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "          \u001b[31mexec\u001b[0m\u001b[1;31m(code, locals())\u001b[0m\n",
      "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m128\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "        File \u001b[35m\"C:\\Python313\\Lib\\subprocess.py\"\u001b[0m, line \u001b[35m414\u001b[0m, in \u001b[35mcheck_call\u001b[0m\n",
      "          retcode = call(*popenargs, **kwargs)\n",
      "        File \u001b[35m\"C:\\Python313\\Lib\\subprocess.py\"\u001b[0m, line \u001b[35m395\u001b[0m, in \u001b[35mcall\u001b[0m\n",
      "          with \u001b[31mPopen\u001b[0m\u001b[1;31m(*popenargs, **kwargs)\u001b[0m as p:\n",
      "               \u001b[31m~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Python313\\Lib\\subprocess.py\"\u001b[0m, line \u001b[35m1039\u001b[0m, in \u001b[35m__init__\u001b[0m\n",
      "          \u001b[31mself._execute_child\u001b[0m\u001b[1;31m(args, executable, preexec_fn, close_fds,\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "                              \u001b[1;31mpass_fds, cwd, env,\u001b[0m\n",
      "                              \u001b[1;31m^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "          ...<5 lines>...\n",
      "                              \u001b[1;31mgid, gids, uid, umask,\u001b[0m\n",
      "                              \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "                              \u001b[1;31mstart_new_session, process_group)\u001b[0m\n",
      "                              \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Python313\\Lib\\subprocess.py\"\u001b[0m, line \u001b[35m1551\u001b[0m, in \u001b[35m_execute_child\u001b[0m\n",
      "          hp, ht, pid, tid = \u001b[31m_winapi.CreateProcess\u001b[0m\u001b[1;31m(executable, args,\u001b[0m\n",
      "                             \u001b[31m~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "                                   \u001b[1;31m# no special security\u001b[0m\n",
      "                                   \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "          ...<4 lines>...\n",
      "                                   \u001b[1;31mcwd,\u001b[0m\n",
      "                                   \u001b[1;31m^^^^\u001b[0m\n",
      "                                   \u001b[1;31mstartupinfo)\u001b[0m\n",
      "                                   \u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "      \u001b[1;35mFileNotFoundError\u001b[0m: \u001b[35m[WinError 2] The system cannot find the file specified\u001b[0m\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/parler-tts.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
